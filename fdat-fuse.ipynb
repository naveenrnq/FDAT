{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c18bb41",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:32.607873Z",
     "iopub.status.busy": "2024-03-15T16:14:32.607489Z",
     "iopub.status.idle": "2024-03-15T16:14:33.713616Z",
     "shell.execute_reply": "2024-03-15T16:14:33.712275Z"
    },
    "papermill": {
     "duration": 1.116188,
     "end_time": "2024-03-15T16:14:33.716131",
     "exception": false,
     "start_time": "2024-03-15T16:14:32.599943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0378fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:33.729068Z",
     "iopub.status.busy": "2024-03-15T16:14:33.728586Z",
     "iopub.status.idle": "2024-03-15T16:14:43.778850Z",
     "shell.execute_reply": "2024-03-15T16:14:43.777217Z"
    },
    "papermill": {
     "duration": 10.059236,
     "end_time": "2024-03-15T16:14:43.781351",
     "exception": false,
     "start_time": "2024-03-15T16:14:33.722115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "\n",
    "class Convlutioanl(nn.Module):\n",
    "    def __init__(self,  in_channel, out_channel):\n",
    "        super(Convlutioanl, self).__init__()\n",
    "        self.padding=(2,2,2,2)\n",
    "        self.conv=nn.Conv2d(in_channel,out_channel,kernel_size=5,padding=0,stride=1)\n",
    "        self.bn=nn.BatchNorm2d(out_channel)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "    def forward(self, input):\n",
    "        out=F.pad(input,self.padding,'replicate')\n",
    "        out=self.conv(out)\n",
    "        out=self.bn(out)\n",
    "        out=self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c525742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.793983Z",
     "iopub.status.busy": "2024-03-15T16:14:43.793601Z",
     "iopub.status.idle": "2024-03-15T16:14:43.800230Z",
     "shell.execute_reply": "2024-03-15T16:14:43.798576Z"
    },
    "papermill": {
     "duration": 0.015929,
     "end_time": "2024-03-15T16:14:43.802748",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.786819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Convlutioanl_out(nn.Module):\n",
    "    def __init__(self,  in_channel, out_channel):\n",
    "        super(Convlutioanl_out, self).__init__()\n",
    "\n",
    "        self.conv=nn.Conv2d(in_channel,out_channel,kernel_size=1,padding=0,stride=1)\n",
    "\n",
    "        self.tanh=nn.Tanh()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        out=self.conv(input)\n",
    "\n",
    "        out=self.tanh(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025952cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.815610Z",
     "iopub.status.busy": "2024-03-15T16:14:43.815184Z",
     "iopub.status.idle": "2024-03-15T16:14:43.823090Z",
     "shell.execute_reply": "2024-03-15T16:14:43.821930Z"
    },
    "papermill": {
     "duration": 0.016822,
     "end_time": "2024-03-15T16:14:43.825326",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.808504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Fem(nn.Module):\n",
    "    def __init__(self,  in_channel, out_channel):\n",
    "        super(Fem, self).__init__()\n",
    "        self.padding = (1, 1, 1, 1)\n",
    "        self.conv=nn.Conv2d(in_channel,out_channel,kernel_size=3,padding=0,stride=1)\n",
    "        self.bn=nn.BatchNorm2d(out_channel)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = F.pad(input, self.padding, 'replicate')\n",
    "        out=self.conv(out)\n",
    "        out=self.bn(out)\n",
    "        out=self.relu(out)\n",
    "        out = F.pad(out, self.padding, 'replicate')\n",
    "        out=self.conv(out)\n",
    "        out = self.bn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29afd9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.839083Z",
     "iopub.status.busy": "2024-03-15T16:14:43.838220Z",
     "iopub.status.idle": "2024-03-15T16:14:43.844963Z",
     "shell.execute_reply": "2024-03-15T16:14:43.843795Z"
    },
    "papermill": {
     "duration": 0.015981,
     "end_time": "2024-03-15T16:14:43.847309",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.831328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Channel_attention(nn.Module):\n",
    "    def __init__(self,  channel, reduction=4):\n",
    "        super(Channel_attention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Conv2d(channel,channel//reduction,1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel//reduction,channel,1))\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self, input):\n",
    "        out=self.avg_pool(input)\n",
    "        out=self.fc(out)\n",
    "        out=self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5208f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.860205Z",
     "iopub.status.busy": "2024-03-15T16:14:43.859854Z",
     "iopub.status.idle": "2024-03-15T16:14:43.865835Z",
     "shell.execute_reply": "2024-03-15T16:14:43.864933Z"
    },
    "papermill": {
     "duration": 0.015272,
     "end_time": "2024-03-15T16:14:43.868332",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.853060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Spatial_attention(nn.Module):\n",
    "    def __init__(self,  channel, reduction=4):\n",
    "        super(Spatial_attention, self).__init__()\n",
    "        self.body=nn.Sequential(\n",
    "            nn.Conv2d(channel, channel//reduction,3,padding=1),\n",
    "            nn.BatchNorm2d( channel//reduction),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(channel // reduction, 1, 3, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.body(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8631139d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.883063Z",
     "iopub.status.busy": "2024-03-15T16:14:43.882374Z",
     "iopub.status.idle": "2024-03-15T16:14:43.898323Z",
     "shell.execute_reply": "2024-03-15T16:14:43.897135Z"
    },
    "papermill": {
     "duration": 0.026306,
     "end_time": "2024-03-15T16:14:43.900675",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.874369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))\n",
    "        coords_flatten = torch.flatten(coords, 1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    def forward(self, x, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "    def flops(self, N):\n",
    "        flops = 0\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06745bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.915240Z",
     "iopub.status.busy": "2024-03-15T16:14:43.914643Z",
     "iopub.status.idle": "2024-03-15T16:14:43.921933Z",
     "shell.execute_reply": "2024-03-15T16:14:43.920715Z"
    },
    "papermill": {
     "duration": 0.017281,
     "end_time": "2024-03-15T16:14:43.924194",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.906913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053ae26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.937884Z",
     "iopub.status.busy": "2024-03-15T16:14:43.937373Z",
     "iopub.status.idle": "2024-03-15T16:14:43.944222Z",
     "shell.execute_reply": "2024-03-15T16:14:43.943226Z"
    },
    "papermill": {
     "duration": 0.016222,
     "end_time": "2024-03-15T16:14:43.946183",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.929961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b71425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.960378Z",
     "iopub.status.busy": "2024-03-15T16:14:43.959817Z",
     "iopub.status.idle": "2024-03-15T16:14:43.979154Z",
     "shell.execute_reply": "2024-03-15T16:14:43.978095Z"
    },
    "papermill": {
     "duration": 0.029406,
     "end_time": "2024-03-15T16:14:43.981625",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.952219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=1, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "        if self.shift_size > 0:\n",
    "            attn_mask = self.calculate_mask(self.input_resolution)\n",
    "        else:\n",
    "            attn_mask = None\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "    def calculate_mask(self, x_size):\n",
    "        H, W = x_size\n",
    "        img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "        h_slices = (slice(0, -self.window_size),\n",
    "                    slice(-self.window_size, -self.shift_size),\n",
    "                    slice(-self.shift_size, None))\n",
    "        w_slices = (slice(0, -self.window_size),\n",
    "                    slice(-self.window_size, -self.shift_size),\n",
    "                    slice(-self.shift_size, None))\n",
    "        cnt = 0\n",
    "        for h in h_slices:\n",
    "            for w in w_slices:\n",
    "                img_mask[:, h, w, :] = cnt\n",
    "                cnt += 1\n",
    "        mask_windows = window_partition(img_mask, self.window_size)\n",
    "        mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "        attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "        attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        return attn_mask\n",
    "    def forward(self, x, x_size):\n",
    "        B,C,H,W= x.shape\n",
    "        x=x.view(B,H,W,C)\n",
    "        shortcut = x\n",
    "        shape=x.view(H*W*B,C)\n",
    "        x = self.norm1(shape)\n",
    "        x = x.view(B, H, W, C)\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)\n",
    "        if self.input_resolution == x_size:\n",
    "            attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "        else:\n",
    "            attn_windows = self.attn(x_windows, mask=self.calculate_mask(x_size).to(x.device))\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        B,H,W,C=x.shape\n",
    "        x=x.view(B,C,H,W)\n",
    "        return x\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        flops += self.dim * H * W\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        flops += self.dim * H * W\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbcfb71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:43.996464Z",
     "iopub.status.busy": "2024-03-15T16:14:43.995902Z",
     "iopub.status.idle": "2024-03-15T16:14:44.004375Z",
     "shell.execute_reply": "2024-03-15T16:14:44.003189Z"
    },
    "papermill": {
     "duration": 0.019232,
     "end_time": "2024-03-15T16:14:44.006642",
     "exception": false,
     "start_time": "2024-03-15T16:14:43.987410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=120, patch_size=4, in_chans=6, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.img_size\n",
    "        if self.norm is not None:\n",
    "            flops += H * W * self.embed_dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4238da1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.021242Z",
     "iopub.status.busy": "2024-03-15T16:14:44.020651Z",
     "iopub.status.idle": "2024-03-15T16:14:44.030950Z",
     "shell.execute_reply": "2024-03-15T16:14:44.029782Z"
    },
    "papermill": {
     "duration": 0.020785,
     "end_time": "2024-03-15T16:14:44.033289",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.012504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicLayer(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_size,\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "    def forward(self, x, x_size):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, x_size)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        if self.downsample is not None:\n",
    "            flops += self.downsample.flops()\n",
    "        return flops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364afe52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.047369Z",
     "iopub.status.busy": "2024-03-15T16:14:44.046779Z",
     "iopub.status.idle": "2024-03-15T16:14:44.058512Z",
     "shell.execute_reply": "2024-03-15T16:14:44.057356Z"
    },
    "papermill": {
     "duration": 0.021872,
     "end_time": "2024-03-15T16:14:44.061074",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.039202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "    def __init__(self, img_size=120,patch_size=4,embed_dim=96,num_heads=8, window_size=1,in_channel=2, out_channel=16,output_channel=1,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., patch_norm=True,depth=2,downsample=None,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm,use_checkpoint=False ):\n",
    "        super(MODEL, self).__init__()\n",
    "        self.convolutional = Convlutioanl(in_channel, out_channel)\n",
    "        self.convolutional_out =  Convlutioanl_out( out_channel,output_channel)\n",
    "\n",
    "        self.fem = Fem(out_channel, out_channel)\n",
    "        self.cam = Channel_attention(out_channel)\n",
    "        self.sam = Spatial_attention(out_channel)\n",
    "        self.relu=nn.ReLU(True)\n",
    "        self.patch_norm = patch_norm\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=embed_dim, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.basicLayer=BasicLayer(dim= out_channel,\n",
    "                                   input_resolution=(patches_resolution[0],patches_resolution[1]),\n",
    "                                         depth=depth,\n",
    "                                         num_heads=num_heads,\n",
    "                                         window_size=window_size,\n",
    "                                         mlp_ratio=mlp_ratio,\n",
    "                                         qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                         drop=drop, attn_drop=attn_drop,\n",
    "                                         drop_path=drop_path,\n",
    "                                         norm_layer=norm_layer,\n",
    "                                         downsample=downsample,\n",
    "                                         use_checkpoint=use_checkpoint)\n",
    "    def forward(self, input):\n",
    "        convolutioanl = self.convolutional(input)\n",
    "        fem=self.fem(convolutioanl)\n",
    "        cam=self.cam(fem)\n",
    "        sam=self.sam(fem)\n",
    "        fem_cam=fem*cam\n",
    "        fem_sam=fem*sam\n",
    "        add=fem_cam+fem_sam+convolutioanl\n",
    "        encode=self.relu(add)\n",
    "        encode_size = (encode.shape[2], encode.shape[3])\n",
    "        Transformer=self.basicLayer(encode, encode_size)\n",
    "        de_fem=self.fem(Transformer)\n",
    "        de_cam=self.cam(de_fem)\n",
    "        de_sam=self.sam(de_fem)\n",
    "        de_fem_cam=de_fem*de_cam\n",
    "        de_fem_sam=de_fem*de_sam\n",
    "        de_add=de_fem_cam+de_fem_sam+ de_fem\n",
    "        out=self.convolutional_out (de_add)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5b3599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.076301Z",
     "iopub.status.busy": "2024-03-15T16:14:44.075932Z",
     "iopub.status.idle": "2024-03-15T16:14:44.081670Z",
     "shell.execute_reply": "2024-03-15T16:14:44.080444Z"
    },
    "papermill": {
     "duration": 0.016496,
     "end_time": "2024-03-15T16:14:44.084309",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.067813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def ir_loss (fused_result,input_ir ):\n",
    "    a=fused_result-input_ir\n",
    "    b=torch.square(fused_result-input_ir)\n",
    "    c=torch.mean(torch.square(fused_result-input_ir))\n",
    "    ir_loss=c\n",
    "    return ir_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a34b3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.098508Z",
     "iopub.status.busy": "2024-03-15T16:14:44.097500Z",
     "iopub.status.idle": "2024-03-15T16:14:44.101869Z",
     "shell.execute_reply": "2024-03-15T16:14:44.101225Z"
    },
    "papermill": {
     "duration": 0.013618,
     "end_time": "2024-03-15T16:14:44.103886",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.090268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vi_loss (fused_result , input_vi):\n",
    "    vi_loss=torch.mean(torch.square(fused_result-input_vi))\n",
    "    return vi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516ea55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.118107Z",
     "iopub.status.busy": "2024-03-15T16:14:44.117381Z",
     "iopub.status.idle": "2024-03-15T16:14:44.123230Z",
     "shell.execute_reply": "2024-03-15T16:14:44.122311Z"
    },
    "papermill": {
     "duration": 0.015481,
     "end_time": "2024-03-15T16:14:44.125446",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.109965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ssim_loss (fused_result,input_ir,input_vi ):\n",
    "    ssim_loss=ssim(fused_result,torch.maximum(input_ir,input_vi))\n",
    "\n",
    "    return ssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c24916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.141271Z",
     "iopub.status.busy": "2024-03-15T16:14:44.139738Z",
     "iopub.status.idle": "2024-03-15T16:14:44.147020Z",
     "shell.execute_reply": "2024-03-15T16:14:44.146004Z"
    },
    "papermill": {
     "duration": 0.017954,
     "end_time": "2024-03-15T16:14:44.149506",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.131552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gra_loss( fused_result,input_ir, input_vi):\n",
    "    gra_loss =torch.norm( Gradient(fused_result)- torch.maximum(Gradient(input_ir), Gradient(input_vi)))\n",
    "    return gra_loss\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "959b6667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.163928Z",
     "iopub.status.busy": "2024-03-15T16:14:44.163258Z",
     "iopub.status.idle": "2024-03-15T16:14:44.168683Z",
     "shell.execute_reply": "2024-03-15T16:14:44.167444Z"
    },
    "papermill": {
     "duration": 0.015813,
     "end_time": "2024-03-15T16:14:44.171453",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.155640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_window(window_size, channel=1):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b693770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.186003Z",
     "iopub.status.busy": "2024-03-15T16:14:44.185401Z",
     "iopub.status.idle": "2024-03-15T16:14:44.195005Z",
     "shell.execute_reply": "2024-03-15T16:14:44.194030Z"
    },
    "papermill": {
     "duration": 0.018881,
     "end_time": "2024-03-15T16:14:44.197038",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.178157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ssim(img1, img2, window_size=11, window=None, val_range=None):\n",
    "    if val_range is None:\n",
    "        if torch.max(img1) > 128:\n",
    "            max_val = 255\n",
    "        else:\n",
    "            max_val = 1\n",
    "\n",
    "        if torch.min(img1) < -0.5:\n",
    "            min_val = -1\n",
    "        else:\n",
    "            min_val = 0\n",
    "        L = max_val - min_val\n",
    "    else:\n",
    "        L = val_range\n",
    "\n",
    "    padd = 0\n",
    "    (_, channel, height, width) = img1.size()\n",
    "    if window is None:\n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channel).to(img1.device)\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)\n",
    "    ret = ssim_map.mean()\n",
    "    return 1-ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca24fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.211952Z",
     "iopub.status.busy": "2024-03-15T16:14:44.210776Z",
     "iopub.status.idle": "2024-03-15T16:14:44.219743Z",
     "shell.execute_reply": "2024-03-15T16:14:44.218274Z"
    },
    "papermill": {
     "duration": 0.018838,
     "end_time": "2024-03-15T16:14:44.222153",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.203315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class gradient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gradient, self).__init__()\n",
    "        x_kernel = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "        y_kernel = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "        x_kernel = torch.FloatTensor(x_kernel).unsqueeze(0).unsqueeze(0)\n",
    "        y_kernel = torch.FloatTensor(y_kernel).unsqueeze(0).unsqueeze(0)\n",
    "        self.x_weight = nn.Parameter(data=x_kernel, requires_grad=False)\n",
    "        self.y_weight = nn.Parameter(data=y_kernel, requires_grad=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_grad = torch.nn.functional.conv2d(input, self.x_weight, padding=1)\n",
    "        y_grad = torch.nn.functional.conv2d(input, self.y_weight, padding=1)\n",
    "        gradRes = torch.mean((x_grad + y_grad).float())\n",
    "        return gradRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c320192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.236604Z",
     "iopub.status.busy": "2024-03-15T16:14:44.236235Z",
     "iopub.status.idle": "2024-03-15T16:14:44.242842Z",
     "shell.execute_reply": "2024-03-15T16:14:44.241066Z"
    },
    "papermill": {
     "duration": 0.016974,
     "end_time": "2024-03-15T16:14:44.245431",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.228457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Gradient(x):\n",
    "    gradient_model =gradient().to(device)\n",
    "    g = gradient_model(x)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab489de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.261944Z",
     "iopub.status.busy": "2024-03-15T16:14:44.261567Z",
     "iopub.status.idle": "2024-03-15T16:14:44.369536Z",
     "shell.execute_reply": "2024-03-15T16:14:44.368018Z"
    },
    "papermill": {
     "duration": 0.119274,
     "end_time": "2024-03-15T16:14:44.371954",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.252680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "device = torch.device('cuda:0')\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cacc2b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.386670Z",
     "iopub.status.busy": "2024-03-15T16:14:44.386265Z",
     "iopub.status.idle": "2024-03-15T16:14:44.393560Z",
     "shell.execute_reply": "2024-03-15T16:14:44.392159Z"
    },
    "papermill": {
     "duration": 0.017579,
     "end_time": "2024-03-15T16:14:44.395819",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.378240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetDataset(Dataset):\n",
    "    def __init__(self, imageFolderDataset, transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ir='...'\n",
    "        vi='...'\n",
    "\n",
    "        ir = Image.open(ir).convert('L')\n",
    "        vi = Image.open(vi).convert('L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            tran = transforms.ToTensor()\n",
    "            ir=tran(ir)\n",
    "            vi= tran(vi)\n",
    "            input = torch.cat((ir, vi), -3)\n",
    "            return input, ir,vi\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ca1734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.411218Z",
     "iopub.status.busy": "2024-03-15T16:14:44.409928Z",
     "iopub.status.idle": "2024-03-15T16:14:44.417233Z",
     "shell.execute_reply": "2024-03-15T16:14:44.415996Z"
    },
    "papermill": {
     "duration": 0.017443,
     "end_time": "2024-03-15T16:14:44.419653",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.402210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65bfad63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.433672Z",
     "iopub.status.busy": "2024-03-15T16:14:44.433351Z",
     "iopub.status.idle": "2024-03-15T16:14:44.444615Z",
     "shell.execute_reply": "2024-03-15T16:14:44.442892Z"
    },
    "papermill": {
     "duration": 0.02139,
     "end_time": "2024-03-15T16:14:44.447313",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.425923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader_ir,train_loader_vi, model, criterion_ir, criterion_vi,criterion_ssim,criterion_gra,optimizer, epoch, scheduler=None):\n",
    "    losses = AverageMeter()\n",
    "    losses_ir = AverageMeter()\n",
    "    losses_vi = AverageMeter()\n",
    "    losses_ssim = AverageMeter()\n",
    "    losses_gra= AverageMeter()\n",
    "    weight = [1, 1,10,100]\n",
    "    model.train()\n",
    "\n",
    "    for i, (input,ir,vi)  in tqdm(enumerate(train_loader_ir), total=len(train_loader_ir)):\n",
    "\n",
    "\n",
    "        input = input.cuda()\n",
    "\n",
    "        ir=ir.cuda()\n",
    "        vi=vi.cuda()\n",
    "\n",
    "        out = model(input)\n",
    "\n",
    "        loss_ir = weight[0] * criterion_ir(out, ir)\n",
    "        loss_vi = weight[1] * criterion_vi(out, vi)\n",
    "        loss_ssim= weight[2] * criterion_ssim(out,ir, vi)\n",
    "        loss_gra = weight[3] * criterion_gra(out, ir,vi)\n",
    "        loss = loss_ir + loss_vi+loss_ssim+ loss_gra\n",
    "\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        losses_ir.update(loss_ir.item(), input.size(0))\n",
    "        losses_vi.update(loss_vi.item(), input.size(0))\n",
    "        losses_ssim.update(loss_ssim.item(), input.size(0))\n",
    "        losses_gra.update(loss_gra.item(), input.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    log = OrderedDict([\n",
    "        ('loss', losses.avg),\n",
    "        ('loss_ir', losses_ir.avg),\n",
    "        ('loss_vi', losses_vi.avg),\n",
    "        ('loss_ssim', losses_ssim.avg),\n",
    "        ('loss_gra', losses_gra.avg),\n",
    "    ])\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b226b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.462610Z",
     "iopub.status.busy": "2024-03-15T16:14:44.461965Z",
     "iopub.status.idle": "2024-03-15T16:14:44.474022Z",
     "shell.execute_reply": "2024-03-15T16:14:44.472981Z"
    },
    "papermill": {
     "duration": 0.022504,
     "end_time": "2024-03-15T16:14:44.476327",
     "exception": false,
     "start_time": "2024-03-15T16:14:44.453823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    if not os.path.exists('models/%s'):\n",
    "        os.makedirs('models/%s')\n",
    "\n",
    "    with open('models/%s/args.txt' , arch+timestamp, 'w') as f:\n",
    "        for arg in vars(args):\n",
    "            print('%s: %s' %(arg, getattr(args, arg)), file=f)\n",
    "\n",
    "    joblib.dump(args, 'models/%s/args.pkl' , arch+timestamp)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    training_dir_ir = \"...\"\n",
    "    folder_dataset_train_ir = glob.glob(training_dir_ir )\n",
    "    training_dir_vi = \"...\"\n",
    "\n",
    "    folder_dataset_train_vi= glob.glob(training_dir_vi )\n",
    "\n",
    "    transform_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                                               (0.229, 0.224, 0.225))\n",
    "                                          ])\n",
    "\n",
    "    dataset_train_ir = GetDataset(imageFolderDataset=folder_dataset_train_ir,\n",
    "                                                  transform=transform_train)\n",
    "    dataset_train_vi = GetDataset(imageFolderDataset=folder_dataset_train_vi,\n",
    "                                  transform=transform_train)\n",
    "\n",
    "    train_loader_ir = DataLoader(dataset_train_ir,\n",
    "                              shuffle=True,\n",
    "                              batch_size=128)\n",
    "    train_loader_vi = DataLoader(dataset_train_vi,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=128)\n",
    "    model = net(in_channel=2)\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "        model.cuda()\n",
    "\n",
    "    else:\n",
    "        model = model\n",
    "    criterion_ir = ir_loss\n",
    "    criterion_vi = vi_loss\n",
    "    criterion_ssim = ssim_loss\n",
    "    criterion_gra = gra_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr= (1e-3),\n",
    "                           betas= (0.9, 0.999) , eps= (1e-8))\n",
    "    log = pd.DataFrame(index=[],\n",
    "                       columns=['epoch',\n",
    "                                'loss',\n",
    "                                'loss_ir',\n",
    "                                'loss_vi',\n",
    "                                'loss_ssim',\n",
    "                                'loss_gra',\n",
    "                                ])\n",
    "\n",
    "    for epoch in range(10):\n",
    "\n",
    "        train_log = train(args, train_loader_ir,train_loader_vi, model, criterion_ir, criterion_vi,criterion_ssim,criterion_gra, optimizer, epoch)\n",
    "        tmp = pd.Series([\n",
    "            epoch + 1,\n",
    "            train_log['loss'],\n",
    "            train_log['loss_ir'],\n",
    "            train_log['loss_vi'],\n",
    "            train_log['loss_ssim'],\n",
    "            train_log['loss_gra'],\n",
    "        ], index=['epoch', 'loss', 'loss_ir', 'loss_vi', 'loss_ssim', 'loss_gra'])\n",
    "\n",
    "        log = log.append(tmp, ignore_index=True)\n",
    "        log.to_csv('models/%s/log.csv' , arch+timestamp, index=False)\n",
    "\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            torch.save(model.state_dict(), 'models/%s/model_{}.pth'.format(epoch+1) , arch+timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb9073a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:14:44.491003Z",
     "iopub.status.busy": "2024-03-15T16:14:44.490655Z",
     "iopub.status.idle": "2024-03-15T16:14:44.955189Z",
     "shell.execute_reply": "2024-03-15T16:14:44.953798Z"
    },
    "papermill": {
     "duration": 0.474015,
     "end_time": "2024-03-15T16:14:44.956869",
     "exception": true,
     "start_time": "2024-03-15T16:14:44.482854",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/args.txt\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[43march\u001b[49m\u001b[38;5;241m+\u001b[39mtimestamp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(args):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(arg, \u001b[38;5;28mgetattr\u001b[39m(args, arg)), file\u001b[38;5;241m=\u001b[39mf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arch' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aa2ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3608d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.976391,
   "end_time": "2024-03-15T16:14:46.791889",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-15T16:14:29.815498",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
